=======================================================
Namespace:  Quota, LimitRange
-------------------------------------------------------

namespace:
1) quota, LimitRange는 


=======================================================
POD:  init container
-------------------------------------------------------
-개념:
  앱컨터이너 실행 전ㅔ 미리 동작시킬 컨테이너
  본 컨테이너가 실행되기 전ㅔ 사ㄴ 작업이 필요한 경우 사용
  초기화 컨테이너가 모두 실행된 후에 앱 컨테이너를 실행
  https://kubernetes.io/ko/docs/concepts/workloads/pods/init-containers/


nano init-container-myapp-pod.yaml
---
apiVersion: v1
kind: Pod
metadata:
  name: myapp-pod
  labels:
    app: myapp
spec:
  containers:
  - name: myapp-container
    image: busybox:1.28
    command: ['sh', '-c', 'echo The app is running! && sleep 3600']
  initContainers:
  - name: init-myservice
    image: busybox:1.28
    command: ['sh', '-c', "until nslookup myservice.$(cat /var/run/secrets/kubernetes.io/serviceaccount/namespace).svc.cluster.local; do echo waiting for myservice; sleep 2; done"]
  - name: init-mydb
    image: busybox:1.28
    command: ['sh', '-c', "until nslookup mydb.$(cat /var/run/secrets/kubernetes.io/serviceaccount/namespace).svc.cluster.local; do echo waiting for mydb; sleep 2; done"]
---

nano init-container-myservice.yaml
---
apiVersion: v1
kind: Service
metadata:
  name: myservice
spec:
  ports:
  - protocol: TCP
    port: 80
    targetPort: 9376
---

nano init-container-mydb.yaml
---
apiVersion: v1
kind: Service
metadata:
  name: mydb
spec:
  ports:
  - protocol: TCP
    port: 80
    targetPort: 9377
---

root@pod641:~# kubectl get pods  -o wide --watch
NAME                                               READY   STATUS      RESTARTS   AGE   IP              NODE     NOMINATED NODE   READINESS GATES
myapp-pod                                          0/1     Pending     0          0s    <none>          <none>   <none>           <none>
myapp-pod                                          0/1     Pending     0          0s    <none>          pod641   <none>           <none>
myapp-pod                                          0/1     Init:0/2    0          0s    <none>          pod641   <none>           <none>
myapp-pod                                          0/1     Init:0/2    0          1s    <none>          pod641   <none>           <none>
myapp-pod                                          0/1     Init:0/2    0          6s    172.28.17.115   pod641   <none>           <none>
myapp-pod                                          0/1     Init:1/2    0          44s   172.28.17.115   pod641   <none>           <none>
myapp-pod                                          0/1     Init:1/2    0          45s   172.28.17.115   pod641   <none>           <none>
myapp-pod                                          0/1     PodInitializing   0          76s   172.28.17.115   pod641   <none>           <none>
myapp-pod                                          1/1     Running           0          77s   172.28.17.115   pod641   <none>           <none>

kubectl delete  -f init-container-mydb.yaml
kubectl delete -f init-container-myservice.yaml
kubectl delete -f init-container-myapp-pod.yaml



=======================================================
POD: infra container
-------------------------------------------------------
-개념:
  .POD가 만들어 질때 내부적으로 숨겨진 pause container가 하나씩 만들어 진다.
  .POD가 실행될 때 POD의 인프라를 만들어 주는 역할


kubectl run nginxweb --image=nginx:latest --port=80 

docker container ls

root@pod641:~/KubernetesLearning# docker ps | grep nginxweb
bc751da6eff5        nginx                                                    "/docker-entrypoint.…"   26 seconds ago      Up 26 seconds                                                                      k8s_nginxweb_nginxweb_default_e2d9f47d-5faf-44d8-a826-a247d8d9f366_0
1da7cdf74670        k8s.gcr.io/pause:3.2                                     "/pause"                 31 seconds ago      Up 30 seconds                                                                      k8s_POD_nginxweb_default_e2d9f47d-5faf-44d8-a826-a247d8d9f366_0
root@pod641:~/KubernetesLearning#


=======================================================
POD: static pod
-------------------------------------------------------
-개념: 
  .POD의 생성은 API-Server로 들어온 요청을 Scheduler가 etcd DB를 읽어서 만들어질 node를 결정해 주면 Controler-Manager가 그 노드의 kubelet daemon과 통신해서 만들어 주는 절차를 거치는데
  .static pod는 각각의 노드에 kubelet daemon이 관리하는 특별한 디렉토리에 .yaml을 넣어주면 kubelet이 알아서 자동적으로 수행해 주는 pod를 말함
  ..yaml 파일을 지우면 알아서 지워짐
  .즉, kubelet daemon에 의해 동작하는 pod를 static pod라 함.
  .API 서버의 도움없이 특정 노드에 있는 kubelet 데몬에 의해 직접 관리
  ./etc/kubernetes/mainfest/ 디렉토리에 K8s yaml파일을 저장 시 적용됨


  nano /var/lib/kubelet/config.yaml
  ...
  staticPodPath: /etc/kubernetes/manifests
  ...

  디렉토리 수정시 kubelet데몬 재-실행
  #systemctl restart kubelet


-kubelet daemon
root@pod641:/var/lib/kubelet# ll
total 44
drwx------  8 root root 4096 Apr 11 07:54 ./
drwxr-xr-x 65 root root 4096 Apr 26 11:59 ../
-rw-r--r--  1 root root  921 Apr 11 07:54 config.yaml
-rw-------  1 root root   62 Apr 11 07:54 cpu_manager_state
drwxr-xr-x  2 root root 4096 Apr 11 07:54 device-plugins/
-rw-r--r--  1 root root   93 Apr 11 07:54 kubeadm-flags.env
drwxr-xr-x  2 root root 4096 Apr 11 07:54 pki/
drwxr-x---  2 root root 4096 Apr 11 07:54 plugins/
drwxr-x---  2 root root 4096 Apr 11 07:54 plugins_registry/
drwxr-x---  2 root root 4096 Apr 11 07:54 pod-resources/
drwxr-x--- 22 root root 4096 Jun 14 08:08 pods/
root@pod641:/var/lib/kubelet#


cat /var/lib/kubelet/config.yaml
...
staticPodPath: /etc/kubernetes/manifests
...


-/etc/kubernetes/manifests

root@pod641:/etc/kubernetes/manifests# ll
total 24
drwx------ 2 root root 4096 Apr 11 07:54 ./
drwxr-xr-x 4 root root 4096 Apr 11 07:54 ../
-rw------- 1 root root 2183 Apr 11 07:54 etcd.yaml
-rw------- 1 root root 3818 Apr 11 07:54 kube-apiserver.yaml
-rw------- 1 root root 3315 Apr 11 07:54 kube-controller-manager.yaml
-rw------- 1 root root 1385 Apr 11 07:54 kube-scheduler.yaml
root@pod641:/etc/kubernetes/manifests#


=======================================================
POD: Resource 할당방법
-------------------------------------------------------
-개념: 
  .K8s는 크게 Namespace(quota, LimitRange)단위와 개별 리소스(pod, service, ...)단위의 호스트의 자원을 제한 하는 방법을 제공
  .Namespace(quota, LimitRange)는 관리자가 통제함
  .Namespace내에 생기는 개별POD들은 개발자가 통제할 수 있음
  .Request와 Limits 등 2가지 방식 제공
  .Resource Requests: POD를 수행하기 위한 최소 리소스 양을 요청, 만약 현재 자원이 존재하지 않으면 Schedule는 자원의 여유가 생길 때까지 pending상태를 유지시킴
  .Resource Limits: 파트가 사용할 수 있는 최대 리소스 양을 제한, Limit을 초과해서 사용되는 파트는 강제종료(OOM Kill-Restart)되며 다시 스케쥴링 되기위해 Pending상태로 변함

-K8s Resource 단위:
  .CPU는 Core숫자 또는 m, milli core로 표현
  .1MB != 1024KB (X)
  .1MB == 1000KB
  .1MiB == 1024KiB



=======================================================
POD: 환경변수 할당법
-------------------------------------------------------
-개념:
  .환경변수를 이용해 컨터이너에게 데이터 전달하기
  .POD내의 컨테이너가 실행될 때 필요로 하는 변수
  .컨테이너 만들때 개발자, 엔지니어가 미리 정의
  .새로운 변수 및 POD실행시 미리 정의된 컨테이너의 환경변수를 변경할 수도 있음.


nano env-nginx-pod.yaml

---
apiVersion: v1
kind: Pod
metadata:
  labels:
    run: env-nginx-pod
  name: env-nginx-pod
spec:
  containers:
  - image: nginx:latest
    name: env-nginx-container
    ports:
    - containerPort: 80
    env:
    - name: MYENV
      value: "HelloENV"
---

kubectl apply -f env-nginx-pod.yaml
kubectl exec -it env-nginx-pod -- env
kubectl exec -it env-nginx-pod -- env | grep MYENV


=======================================================
K8s Controller: Deployment Rolling Update를 Annotations을 이용하는 방법
-------------------------------------------------------

nano nginx-Deployment-2-annotations.yaml 

---
apiVersion: apps/v1
#kind: ReplicaSet
kind: Deployment
metadata:
  name: nginx-deployment
  annotations:
    kubernetes.io/change-cause: verstion 1.21
spec:
# 원래 default 값이, update가능
  progressDeadlineSeconds: 600
  revisionHistoryLimit: 10
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
#
  replicas: 3
  selector:
    matchLabels:
      app: "nginxweb"
    matchExpressions:
    - {key: version, operator: In, values: ["1.20", "1.21", "1.22", "latest"]}
  template:
    metadata:
      name: nginxweb-pod
      labels:
        app: "nginxweb"
        version: "1.21"
    spec:
      containers:
      - name: nginx-container
        image: nginx:1.21
        ports:
        - containerPort: 80
---

kubectl apply  -f nginxweb-Deployment-2-annotations.yaml  
//여기에 --record 옵션을 주지 않음

kubectl get deployment,rs,pod


//이미지 update
nano nginx-Deployment-2-annotations.yaml 
...
  annotations:
    kubernetes.io/change-cause: verstion 1.21 --> 1.22
...
     name: nginxweb-pod
      labels:
        app: "nginxweb"
        version: "1.21" --> 1.22
    spec:
...
    spec:
      containers:
      - name: nginx-container
        image: nginx:1.21 --> 1.22
...

kubectl apply  -f nginxweb-Deployment-2-annotations.yaml 
//여기에 --record 옵션을 주지 않음

kubectl rollout history deployment nginx-deployment
root@pod641:~/KubernetesLearning/K8STraining# kubectl rollout history deployment nginx-deployment
deployment.apps/nginx-deployment
REVISION  CHANGE-CAUSE
1         verstion 1.21
2         verstion 1.22

kubectl delete -f nginxweb-Deployment-2-annotations.yaml 


=======================================================
새로운 노드를 기본 클러스터에 연결시키기 위해서 만료된 토큰 새로 생성하기
-------------------------------------------------------

kubeadm token list
kubeadm token create --ttl 2400h

root@pod641:~/KubernetesLearning/K8STraining# kubeadm token create --ttl 2400h
lpqxog.i7ngaww75f0oahan


//홋트를 클러스트에서 탈퇴시키기 
kubeadm reset 

kubeadm

=======================================================
NGINX Load Balancer 만들기
-------------------------------------------------------
//서버목록 
IP 10.100.0.254: nginx Load Balancer
IP 10.100.0.101: server#1
IP 10.100.0.102: server#2
IP 10.100.0.103: server#3

//NGINX Load Balancer 설정
mkdir -p /etc/nginx
cat << END >> /etc/nginx/nginx.conf 
events {}
stream {
  upstream stream_backend {
    least_conn;
    server 10.100.0.101:6443;
    server 10.100.0.102:6443;
    server 10.100.0.103:6443;
  }
  server {
    listen  6443;
    proxy_pass stream_backend;
    proxy_timeout 300s;
    proxy_connect_timeout 1s;
  }
}
END

//도커로 수행
docker run --name nginx-proxy -v /etc/nginx/nginx.conf:/etc/nginx/nginx.conf:ro --restart=always -p 6443:6443 -d nginx:latest

//테스트
curl 10.100.0.254:6443


=======================================================
Service Type: ClusterIP
-------------------------------------------------------
-개념:
  .내부 파드의 TCP Port를 외부(K8s Cluster, 인터넷)와 통신하기 위하여 파드들의 그룹으로 묶어 단일 진입점(Virtual IP)를 생성
  .ClusterIP는 주로 K8s Cluster내부간의 통신에 사용가능
  .Type 생략시 Default값

nano nginx-service-clusterip.yaml
---
apiVersion: apps/v1
#kind: ReplicaSet
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      "app": "nginxweb"
  template:
    metadata:
      name: nginxweb-pod
      labels:
        "app": "nginxweb"
    spec:
      containers:
      - name: nginx-container
        image: nginx:1.21
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: nginxweb-clusterip-svc
spec:
  #clusterIP: x.y.w.z
  selector:
    "app": "nginxweb"
  ports:
  - protocol: TCP
    port: 8880
    targetPort: 80
  type: ClusterIP
---

kubectl apply -f nginx-service-clusterip.yaml
kubectl get svc

root@pod641:~/KubernetesLearning/K8sTraining/AdvancedTopicYaml# kubectl get svc
NAME                                      TYPE           CLUSTER-IP       EXTERNAL-IP     PORT(S)          AGE
nginxweb-clusterip-svc                    ClusterIP      10.101.52.104    <none>          8880/TCP         3m35s

curl http://10.101.52.104:8880/

kubectl scale deployment nginx-deployment replicas=5


kubectl describe svc nginxweb-clusterip-svc
root@pod641:~/KubernetesLearning/K8sTraining/AdvancedTopicYaml# kubectl describe svc nginxweb-clusterip-svc
Name:              nginxweb-clusterip-svc
Namespace:         default
Labels:            <none>
Annotations:       <none>
Selector:          app=nginxweb
Type:              ClusterIP
IP Families:       <none>
IP:                10.101.52.104
IPs:               10.101.52.104
Port:              <unset>  8880/TCP
TargetPort:        80/TCP
Endpoints:         172.28.17.123:80,172.28.235.201:80,172.28.235.202:80
Session Affinity:  None
Events:            <none>

kubectl delete -f nginx-service-clusterip.yaml

=======================================================
Service Type: NodePort
-------------------------------------------------------
-개념:
  .모든 노드(K8s 호스트)를 대상으로 외부 접속 가능한 포트를 예약
  .Default NodePort범위는 30000~32767
  .ClusterIP를 생성 후 NodePort를 예약
  .ClusterIP는 내부통신용, NodePort는 외부통신용
  .K8s Cluster에 소속된 모든 노드의 공인IP와 예약된 NodePort번호로 외부에서 접속가능

nano nginx-service-nodeport.yaml
---
apiVersion: apps/v1
#kind: ReplicaSet
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      "app": "nginxweb"
  template:
    metadata:
      name: nginxweb-pod
      labels:
        "app": "nginxweb"
    spec:
      containers:
      - name: nginx-container
        image: nginx:1.21
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: nginxweb-nodeport-svc
spec:
  selector:
    "app": "nginxweb"
  ports:
  - protocol: TCP
    port: 8880
    targetPort: 80
    nodePort: 30303
  type: NodePort
---

kubectl apply -f nginx-service-nodeport.yaml

kubectl get svc
root@pod641:~/KubernetesLearning/K8sTraining/AdvancedTopicYaml# kubectl get svc
NAME                                      TYPE           CLUSTER-IP       EXTERNAL-IP     PORT(S)          AGE
nginxweb-nodeport-svc                     NodePort       10.111.118.142   <none>          8880:30303/TCP   3m11s

//모든 노드에서 포트 열린 것 확인
netstat -nltp | grep 30303
root@pod641:~/KubernetesLearning/K8sTraining/AdvancedTopicYaml# netstat -nltp | grep 30303
tcp        0      0 0.0.0.0:30303           0.0.0.0:*               LISTEN      124405/kube-proxy

curl http://모든노드들IP:30303

kubectl delete -f nginx-service-nodeport.yaml


=======================================================
Service Type: Load Balancer
-------------------------------------------------------
-개념:
  .Public Cloud(AWS, Azure, GCP등)에서 운영가능
  .Private Cloud의 경우 OpenStack, K8s 자체적으로 MetaLB등의 서비스 활용
  .LoadBalancer에게 nodeport에 매핑할 공인IP요청
  .NodePort를 예약 후 해당 NodePort로 외부 접근을 허용
  .이름은 Load Balancer이지만 동적IP할당과 비슷함. MetalLB로 부터 공인IP를 동적으로 할당받고, NodePort를 통해 자체 LB기능 제공

nano  nginx-service-LoadBalancer.yaml
---
apiVersion: apps/v1
#kind: ReplicaSet
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      "app": "nginxweb"
  template:
    metadata:
      name: nginxweb-pod
      labels:
        "app": "nginxweb"
    spec:
      containers:
      - name: nginx-container
        image: nginx:1.21
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: nginxweb-loadbalancer-svc
spec:
  selector:
    "app": "nginxweb"
  ports:
  - protocol: TCP
    port: 8880
    targetPort: 80
    nodePort: 30303
  type: LoadBalancer
---

kubectl apply -f  nginx-service-LoadBalancer.yaml

kubectl get svc

root@pod641:~/KubernetesLearning/K8sTraining/AdvancedTopicYaml# kubectl get svc
NAME                                      TYPE           CLUSTER-IP       EXTERNAL-IP     PORT(S)          AGE
nginxweb-loadbalancer-svc                 LoadBalancer   10.104.224.42    218.145.56.86   8880:30303/TCP   8s

kubectl delete -f  nginx-service-LoadBalancer.yaml



=======================================================
Core DNS
-------------------------------------------------------
kubectl get po -n kube-system -l k8s-app=kube-dns
root@pod641:~/KubernetesLearning/K8sTraining# kubectl get po -n kube-system -l k8s-app=kube-dns
NAME                       READY   STATUS    RESTARTS   AGE
coredns-66c59497d4-b4tbw   1/1     Running   0          37d
coredns-66c59497d4-ht8r2   1/1     Running   0          37d


kubectl get svc -n kube-system -l k8s-app=kube-dns
root@pod641:~/KubernetesLearning/K8sTraining# kubectl get svc -n kube-system -l k8s-app=kube-dns
NAME       TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)                  AGE
kube-dns   ClusterIP   10.96.0.10   <none>        53/UDP,53/TCP,9153/TCP   68d

kubectl describe cm -n kube-system coredns
root@pod641:~/KubernetesLearning/K8sTraining#  kubectl describe cm -n kube-system coredns
Name:         coredns
Namespace:    kube-system
Labels:       <none>
Annotations:  <none>

Data
====
Corefile:
----
.:53 {
    errors
    health {
       lameduck 5s
    }
    ready
    kubernetes cluster.local in-addr.arpa ip6.arpa {
       pods insecure
       fallthrough in-addr.arpa ip6.arpa
       ttl 30
    }
    prometheus :9153
    forward . /etc/resolv.conf {
       max_concurrent 1000
    }
    cache 30
    loop
    reload
    loadbalance
}

Events:  <none>
root@pod641:~/KubernetesLearning/K8sTraining#

kubectl run -it --rm busybox --image=busybox --restart=Never -- cat /etc/resolv.conf

kubectl edit deployments/coredns -n kube-system

kubectl rollout restart -n kube-system deployment/coredns

kubectl edit cm coredns -n kube-system

kubectl get pods -n kube-system -oname |grep coredns |xargs kubectl delete -n kube-system



=======================================================
Service: Headless Service
-------------------------------------------------------
-개념:
  .ClusterIP가 없는 서비스로 단일 집입점이 필요 없을 때 사용
  .Service와 연결된 Pod의 endpoint로 DNS 레코드가 생성됨
  .Pod의 DNS주소: pod-ip-addr.namespace.pod.cluster.local
  .일반 DNS 시스템들의 Name기반 LoadBalancing과 비슷함
    IP IN A 192.168.0.20
          A 192.168.0.21
          A 192.168.0.22
  .K8s Cluster 내부의 POD들 간 이름을 통한 통신이 목적임
  .POD의 이름이 자주 변경되는 것 보다는 stateful POD와 함께 사용함.



nano nginxweb-service-headless.yaml

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginxweb
  template:
    metadata:
      name: nginxweb-pod
      labels:
        app: nginxweb
    spec:
      containers:
      - name: nginx-container
        image: nginx:1.21
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: nginxweb-headless-svc
spec:
  #명시적으로 clusterIP를 None으로 지정하는 것이 headless service
  clusterIP: None
  selector:
    app: nginxweb
  ports:
  - protocol: TCP
    port: 8880
    targetPort: 80
  type: ClusterIP
---

kubectl describe svc nginxweb-headless-svc

root@pod641:~/KubernetesLearning/K8sTraining/AdvancedTopicYaml# kubectl describe svc nginxweb-headless-svc
Name:              nginxweb-headless-svc
Namespace:         default
Labels:            <none>
Annotations:       <none>
Selector:          app=nginxweb
Type:              ClusterIP
IP Families:       <none>
IP:                None
IPs:               None
Port:              <unset>  8880/TCP
TargetPort:        80/TCP
Endpoints:         172.28.17.96:80,172.28.235.201:80,172.28.235.202:80
Session Affinity:  None
Events:            <none>
root@pod641:~/KubernetesLearning/K8sTraining/AdvancedTopicYaml#


root@pod641:~/KubernetesLearning/K8sTraining/AdvancedTopicYaml# kubectl get pods -o wide
NAME                                               READY   STATUS      RESTARTS   AGE   IP               NODE     NOMINATED NODE   READINESS GATES
nginx-deployment-6d6c9f5c49-4s66l                  1/1     Running     0          15m   172.28.235.201   pod642   <none>           <none>
nginx-deployment-6d6c9f5c49-hg7w7                  1/1     Running     0          15m   172.28.235.202   pod642   <none>           <none>
nginx-deployment-6d6c9f5c49-jncjt                  1/1     Running     0          15m   172.28.17.96     pod641   <none>           <none>
ubuntu-pod                                         1/1     Running     1          13m   172.28.235.198   pod642   <none>           <none>


//다른 창에서 ubuntu 또는  centos를 뛰운다.
 kubectl run -it ubuntu-pod --image=mkbahk/ubuntu:tools
  curl http://nginxweb-headless-svc.default.pod.cluster.local
  curl http://202-235-28.172.default.pod.cluster.local
  curl http://nginx-deployment-6d6c9f5c49-jncjt.default.pod.cluster.local



=======================================================
K8s kube-proxy  
-------------------------------------------------------
-개념:
  .Kubernetes Service의 backend구현, 즉 서비스를 만들면 관련 iptables 테이블을 생성함, 관련된 서비스포트로 listenning 하고 있음.
  .endpoint 연결을 위한 iptables 구성
  .nodePort로의 접근과 Pod 연결을 iptables를 통해서 구현
  .모든 node에 kube-proxy 가 돌고 있음.

-kube-proxy 동작모드
  .userspace
    -클라이언드의 서비스 요청을 iptables를 거쳐 kube-proxy가 반아서 연결
    -kubernetes 초기버젼에 감깐 사용
  .iptables
    -default kubernetes network mode
    -kube-proxy는 서비스 API요청 시 iptables rule이 생성
    -클라이언트 연결은 kube-proxy가 받아서 iptables rule을 통해 연결
  .IPVS
    -리눅스 커널이 지원하는 L4 LoadBalancing기술을 이용
    -별도의 ipvs지원 모듈을 설정한 후 적용가능
    -지원 알고리즘:
      rr(round-robin)
      lc(least connection)
      dh(destination hashing)
      sh(source hashing)
      sed(shortest expected delay)
      nc(network queue)

kubectl apply -f nginx-service-nodeport.yaml

root@pod641:~/KubernetesLearning/K8sTraining/AdvancedTopicYaml# kubectl get svc -o wide
NAME                                      TYPE           CLUSTER-IP       EXTERNAL-IP     PORT(S)          AGE   SELECTOR
nginxweb-nodeport-svc                     NodePort       10.102.146.66    <none>          8880:30303/TCP   9s    app=nginxweb


root@pod641:~/KubernetesLearning/K8sTraining/AdvancedTopicYaml# kubectl get pods -o wide
NAME                                               READY   STATUS      RESTARTS   AGE   IP               NODE     NOMINATED NODE   READINESS GATES
nginx-deployment-6d6c9f5c49-4tvg7                  1/1     Running     0          32s   172.28.17.97     pod641   <none>           <none>
nginx-deployment-6d6c9f5c49-5btng                  1/1     Running     0          32s   172.28.235.205   pod642   <none>           <none>
nginx-deployment-6d6c9f5c49-fswrb                  1/1     Running     0          32s   172.28.17.103    pod641   <none>           <none>


root@pod641:~/KubernetesLearning/K8sTraining/AdvancedTopicYaml# iptables -t nat -S | grep 8880
-A KUBE-SERVICES ! -s 172.28.0.0/16 -d 10.102.146.66/32 -p tcp -m comment --comment "default/nginxweb-nodeport-svc cluster IP" -m tcp --dport 8880 -j KUBE-MARK-MASQ
-A KUBE-SERVICES -d 10.102.146.66/32 -p tcp -m comment --comment "default/nginxweb-nodeport-svc cluster IP" -m tcp --dport 8880 -j KUBE-SVC-ZP5HGCA4M42P3U25

root@pod641:~/KubernetesLearning/K8sTraining/AdvancedTopicYaml# iptables -t nat -S | grep 30303
-A KUBE-NODEPORTS -p tcp -m comment --comment "default/nginxweb-nodeport-svc" -m tcp --dport 30303 -j KUBE-MARK-MASQ
-A KUBE-NODEPORTS -p tcp -m comment --comment "default/nginxweb-nodeport-svc" -m tcp --dport 30303 -j KUBE-SVC-ZP5HGCA4M42P3U25

root@pod641:~/KubernetesLearning/K8sTraining/AdvancedTopicYaml# iptables -t nat -S | grep 80
...
-A KUBE-SEP-5QRCKXQNABOYPVG2 -p tcp -m comment --comment "default/nginxweb-nodeport-svc" -m tcp -j DNAT --to-destination 172.28.17.103:80
-A KUBE-SEP-T5U6DNXZECZVJSRC -p tcp -m comment --comment "default/nginxweb-nodeport-svc" -m tcp -j DNAT --to-destination 172.28.17.97:80
-A KUBE-SEP-TFHOGB2QYXAGPUPJ -p tcp -m comment --comment "default/nginxweb-nodeport-svc" -m tcp -j DNAT --to-destination 172.28.235.205:80
...
-A KUBE-SERVICES ! -s 172.28.0.0/16 -d 10.102.146.66/32 -p tcp -m comment --comment "default/nginxweb-nodeport-svc cluster IP" -m tcp --dport 8880 -j KUBE-MARK-MASQ
-A KUBE-SERVICES -d 10.102.146.66/32 -p tcp -m comment --comment "default/nginxweb-nodeport-svc cluster IP" -m tcp --dport 8880 -j KUBE-SVC-ZP5HGCA4M42P3U25
...


=======================================================
K8s Ingress
-------------------------------------------------------
-개념:
  .http나 https를 통해 클러어스 내부의 서비스르 외부로 노출
  .기능:
    -Service에 외부 URL제공
    -트래픽 로드밸런싱
    -SSL 인증서 처리
    -Virtual Hosting을 지정
    -H/W L-4 Switch기능 중 L-7 URL Load LoadBalancing 기능 제공
    -S/W 적으로 로는 NGINX가 전통적으로 이 역할을 수행
    -K8s도 다양한 기능의 Ingress Controller가 있고, 기본적으로 NGINX를 이용한 Controller제공
    -K8s 서버스와 WWW URL를 매팅하는 기술
-Ingress 동작과정
 .Client
    -http://www.helloworld.net/
    -http://www.helloworld.net/login
    -http://www.helloworld.net/order
  .Pod Ingress Controller(NGINX Ingress)
  .Ingress Rules
    -http://www.helloworld.net/ --> svc Main
    -http://www.helloworld.net/login --> svc login
    -http://www.helloworld.net/order --> svc order
  .K8s Service
    -Main Service exposes ClusterIP
    -Login Service exposes ClusterIP
    -Order Service expose ClusterIP

     
wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.2.0/deploy/static/provider/baremetal/deploy.yaml
mv deploy ingress-nginx-controller-deploy.yaml

kubectl apply -f nginx-ingress-controller-deploy.yaml
kubectl apply -f ingress-nginx-controller-deployment-services.yaml
kubectl apply -f ingress-nginx-controller-rule.yaml

curl http://공인ip/

//CoreDNS 이상동작으로 아래 에러발생
root@pod641:~/KubernetesLearning/K8sTraining/AdvancedTopicYaml# kubectl apply -f  ingress-nginx-controller-rule.yaml
Error from server (InternalError): error when creating "ingress-nginx-controller-rule.yaml": Internal error occurred: failed calling webhook "validate.nginx.ingress.kubernetes.io": Post "https://ingress-nginx-controller-admission.ingress-nginx.svc:443/networking/v1/ingresses?timeout=10s": context deadline exceeded
root@pod641:~/KubernetesLearning/K8sTraining/AdvancedTopicYaml#

=======================================================
ConfigMap
-------------------------------------------------------



=======================================================
Secret
-------------------------------------------------------
-개념:
  .ConfigMap: 컨테이너 구성정보를 한곳에 모아서 관리
  .Secret: 컨테이너가 사용하는 Password, auth token, ssh key와 같은 중요한 정보를 저장하고 민감한 구성정보를 base64fh 인코딩해서 한 곳에 모아서 관리
  .민감하지 않는 일반 설정파일 configMap을 사용하고, 민감한 데이타는 secret를 사용
  .Secret 데이타 전달 방법
    -Command-line Argument
    -Environment Variable
    -Volume Mount 
-Secret 만들기:
  .kubectl create secret <Available Commands> name [flags][options]
    -docker-registry: Docker registry에 사용하기 위한 secret를 만듬
    -generic: local file, directory or liternal value로 부터 secret를 만듬
    -tls: TLS secret를 만듦
  . K8s-Docker App.들이 수행 중 외부의 서비스들과 통신하기 위한 보안정보 저장하는 것

-실습:
kubectl create secret tls my-tls-secret --cert=path/to/cert/file --key=path/to/key/file
kubectl create secret docker-registry reg-secret --docker-username=tiger --docker-password=pass --docker-email=mkbahk@gmail.com
kubectl create secret generic mkbahk-secret --from-literal=INTERVAL=2 --from-file=./genid-web-config/




=======================================================
Node/Pod Affinity & antiAffinity
-------------------------------------------------------
-개념:
  .노드의 특정 집합에만 Pod를 스케쥴 하도록 지시
  .nodeSelector: selector field에 명시된 모든 Label이 포함되어 배치됨
  .nodeAffinity: 특정 노드에만 포드가 실핼되도록 유도
  .nodeAffinity 요구사항
    -엄격한 요구: requiredDuringSchedulingIgnoredDuringExecution
    -선호적 요구: preferredDuringSchedulingIgnoredDuringExecution

  .pod 스케쥴링
    -podAffinity: pod를 가깝게 배치하기
    -podAntiAffinity: pod를 더 멀리 배치하기
  .podAffinity 요구사항
    -엄격한 요구: requiredDuringSchedulingIgnoredDuringExecution
    -선호적 요구: preferredDuringSchedulingIgnoredDuringExecution
  .topologyKey
    -노드 label을 이용해 pod의 affinity와 antiAffinity를 설정할 수 있는 또 하나의 기준
    -K8s는 Pod를 스케쥴링 할 때 먼저 Pod의 label을 기준으로 대상 노드를 찾고, 이후 topologyKey 필드를 확인해 해당 노드가 원하는 노드인지 확인





=======================================================
taint & toleration 
-------------------------------------------------------
-개념:
  .node taint, Pod toleration
  .worker node에 taint가 설정된 경우 동일 값의 toleration이 있으면 Pod만 배치
  .toleration이 있는 Pod는 동일한 taint가 있는 node를 포함하여 모든 node에 배치된다.
  .effect 필드 종류
    -NoSchedule: toleration이 맞지 않으면 배치되지 않음
    -PreferNoSchedule: toleration이 맞지 않으면 배치되지 않으나, 클러스터 전체의 리소스가 부족하면 할당됨
    -NoExecute: toleration이 맞으면 동작중인 Pod들을 종료하고 배치

  
=======================================================
cordon 
-------------------------------------------------------
-개념: 
  .노드 스케쥴링 중단(cordon) 및 허용(uncordon)
  .특정 노드에 pod 스케쥴을 금지하거나 해제

kubectl [cordon | uncordon] NODE [options]


=======================================================
drain 
-------------------------------------------------------
-개념: 노드비우기
  .특정 노드에서 동작중인 모든 pod를 제거

-실습:

kubectl drain NODE [options]
  --ignore-daemonsets: DaemonSet-managed pod들은 ignore
  --force=false: RC, RS, job, DaemonSet 또는 StatefulSet에서 관리하지 않는 Pod까지 제거

kubectl drain node2 --force --ignore-daemonsets



=======================================================
인증 및 권한부여 
-------------------------------------------------------
-개념:
  .API 접근제어
  .인증(user, ServiceAccount)
  .권한관리(Role/RoleBinding, ClusterRole/ClusterRoleBinding)

kubectl config view

cat ./kube/config

kubectl get csr 

//관리자가 승인해주는 명령
kubectl certificate approve myuser

//인증서 받기
kubectl get csr/myuser -o yaml

//role만들기
kubectl create role developer-role --verb=create --verb=get --verb=list --verb=update --verb=delete --resource=pods
kubectl create rolebining developer-role-binding-myuser --role=developer-role --user=myservice

kubectl create clusterrole developer-role --verb=create --verb=get --verb=list --verb=update --verb=delete --resource=pods
kubectl create clusterrolebining developer-role-binding-myuser --role=developer-role --user=myservice

kubectl get clusterrole

kubectl describe clusterrole view
kubectl describe clusterrole cluster-admin